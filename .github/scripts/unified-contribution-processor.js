/**
 * SCRIPT UNIFI√â - Remplace tous les autres scripts de traitement
 * Traite les contributions GitHub Issues directement vers entries.json
 */
const { Octokit } = require('@octokit/rest');
const fs = require('fs-extra');
const path = require('path');
const sharp = require('sharp');

const octokit = new Octokit({ auth: process.env.GITHUB_TOKEN });
const REPO_OWNER = 'CollectifIleFeydeau';
const REPO_NAME = 'community-content';

/**
 * Script unifi√© pour traiter les contributions communautaires
 * Remplace tous les anciens scripts (process-contribution.js, sync-issues.js, etc.)
 * 
 * CLOUDINARY INTEGRATION:
 * - Les images sont upload√©es vers Cloudinary depuis le frontend
 * - Ce script r√©cup√®re les URLs Cloudinary depuis les issues GitHub
 * - Pas de traitement d'image n√©cessaire (Cloudinary g√®re tout)
 * - Fallback vers base64 pour r√©trocompatibilit√©
 * 
 * Fonctionnalit√©s :
 * - R√©cup√®re les issues GitHub ouvertes
 * - Parse le contenu des contributions (texte + URLs Cloudinary)
 * - Traite les images base64 (ancien syst√®me uniquement)
 * - Met √† jour entries.json avec URLs Cloudinary
 * - Ferme les issues trait√©es
 */

async function main() {
  console.log(' Traitement unifi√© des contributions...');
  
  try {
    // Debug: V√©rifier le token et les permissions
    console.log('üîç V√©rification du token GitHub...');
    console.log(`Repository cible: ${REPO_OWNER}/${REPO_NAME}`);
    console.log(`Token pr√©sent: ${process.env.GITHUB_TOKEN ? 'OUI' : 'NON'}`);
    
    // Test d'acc√®s au repository
    try {
      const { data: repo } = await octokit.rest.repos.get({
        owner: REPO_OWNER,
        repo: REPO_NAME
      });
      console.log(`‚úÖ Repository trouv√©: ${repo.full_name}`);
      console.log(`üìä Issues activ√©es: ${repo.has_issues}`);
    } catch (repoError) {
      console.error('‚ùå Erreur acc√®s repository:', repoError.message);
      console.error('üí° V√©rifiez que le repository existe et que le token a les bonnes permissions');
      throw repoError;
    }
    
    // 1. R√©cup√©rer toutes les issues avec le label "contribution" (ouvertes ET ferm√©es)
    console.log('üìã Recherche des issues avec label "contribution"...');
    
    let openIssues = [];
    let closedIssues = [];
    
    try {
      const { data: openData } = await octokit.rest.issues.listForRepo({
        owner: REPO_OWNER,
        repo: REPO_NAME,
        labels: 'contribution',
        state: 'open'
      });
      openIssues = openData;
      console.log(`‚úÖ ${openIssues.length} contributions ouvertes trouv√©es`);
    } catch (openError) {
      console.error('‚ùå Erreur r√©cup√©ration issues ouvertes:', openError.message);
      // Continuer m√™me si erreur
    }
    
    try {
      const { data: closedData } = await octokit.rest.issues.listForRepo({
        owner: REPO_OWNER,
        repo: REPO_NAME,
        labels: 'contribution',
        state: 'closed'
      });
      closedIssues = closedData;
      console.log(`‚úÖ ${closedIssues.length} contributions ferm√©es trouv√©es`);
    } catch (closedError) {
      console.error('‚ùå Erreur r√©cup√©ration issues ferm√©es:', closedError.message);
      // Continuer m√™me si erreur
    }
    
    // Debug: Lister toutes les issues pour voir ce qui existe
    try {
      const { data: allIssues } = await octokit.rest.issues.listForRepo({
        owner: REPO_OWNER,
        repo: REPO_NAME,
        state: 'all',
        per_page: 10
      });
      console.log(`üîç Total issues dans le repository: ${allIssues.length}`);
      if (allIssues.length > 0) {
        console.log('üìù Exemples d\'issues trouv√©es:');
        allIssues.slice(0, 3).forEach(issue => {
          console.log(`  - #${issue.number}: "${issue.title}" [${issue.state}] Labels: ${issue.labels.map(l => l.name).join(', ')}`);
        });
      }
    } catch (debugError) {
      console.warn('‚ö†Ô∏è Impossible de lister toutes les issues:', debugError.message);
    }
    
    // 2. Charger entries.json existant
    let entries = { entries: [] };
    const entriesPath = path.join(process.cwd(), 'entries.json');
    
    if (fs.existsSync(entriesPath)) {
      entries = JSON.parse(fs.readFileSync(entriesPath, 'utf8'));
    }
    
    // 3. Traiter les issues ouvertes (nouvelles contributions)
    if (openIssues.length > 0) {
      console.log(`üîÑ Traitement de ${openIssues.length} contributions ouvertes...`);
      for (const issue of openIssues) {
        await processIssue(issue, entries);
      }
    } else {
      console.log('‚ÑπÔ∏è Aucune contribution ouverte √† traiter');
    }
    
    // 4. Marquer les issues ferm√©es comme "rejected" dans entries.json
    if (closedIssues.length > 0) {
      console.log(`üóëÔ∏è Traitement de ${closedIssues.length} contributions ferm√©es...`);
      for (const closedIssue of closedIssues) {
        await markIssueAsRejected(closedIssue, entries);
      }
    } else {
      console.log('‚ÑπÔ∏è Aucune contribution ferm√©e √† traiter');
    }
    
    // 4. Limiter le nombre d'entr√©es pour √©viter un fichier trop volumineux
    if (entries.entries.length > 100) {
      console.log(`‚ö†Ô∏è Limitation: ${entries.entries.length} entr√©es trouv√©es, conservation des 100 plus r√©centes`);
      entries.entries = entries.entries
        .sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime())
        .slice(0, 100);
    }
    
    // 5. Sauvegarder entries.json (format compact pour r√©duire la taille)
    fs.writeFileSync(entriesPath, JSON.stringify(entries, null, 1));
    console.log('üíæ entries.json mis √† jour');
    
    // 6. Fermer les issues ouvertes trait√©es
    for (const issue of openIssues) {
      await octokit.rest.issues.update({
        owner: REPO_OWNER,
        repo: REPO_NAME,
        issue_number: issue.number,
        state: 'closed',
        labels: ['contribution', 'processed']
      });
      console.log(`‚úÖ Issue #${issue.number} ferm√©e`);
    }
    
  } catch (error) {
    console.error('‚ùå Erreur:', error);
    process.exit(1);
  }
}

async function processIssue(issue, entries) {
  try {
    console.log(`üìù Traitement issue #${issue.number}: ${issue.title}`);
    
    // Parser le contenu de l'issue
    const contribution = parseIssueBody(issue.body);
    
    // Fallback: extraire type et nom depuis le titre si pas trouv√© dans le body
    if (!contribution.type || !contribution.displayName) {
      const titleMatch = issue.title.match(/^(\w+):\s*(.+)$/);
      if (titleMatch) {
        if (!contribution.type) contribution.type = titleMatch[1];
        if (!contribution.displayName) contribution.displayName = titleMatch[2];
      }
    }
    
    // Valeurs par d√©faut
    if (!contribution.displayName) contribution.displayName = 'Anonyme';
    if (!contribution.type) contribution.type = 'photo';
    
    // Utiliser l'ID bas√© sur le num√©ro d'issue pour permettre la suppression
    contribution.id = `issue-${issue.number}`;
    contribution.timestamp = issue.created_at;
    contribution.likes = 0;
    contribution.likedBy = [];
    contribution.moderation = {
      status: 'approved',
      moderatedAt: new Date().toISOString()
    };
    
    // üå©Ô∏è CLOUDINARY: Traiter l'image si c'est une photo
    if (contribution.type === 'photo') {
      if (contribution.imageUrl) {
        // üå©Ô∏è CLOUDINARY: URL Cloudinary - utiliser directement (pas de traitement n√©cessaire)
        // Cloudinary g√®re automatiquement le redimensionnement et l'optimisation
        console.log(`üå©Ô∏è Utilisation URL Cloudinary: ${contribution.imageUrl}`);
        contribution.thumbnailUrl = contribution.imageUrl; // M√™me URL pour thumbnail
      } else if (contribution.imageData) {
        // üì∑ LEGACY: Base64 - traiter et sauvegarder (ancien syst√®me)
        console.log(`üì∑ Traitement image base64 (ancien syst√®me)`);
        await processImage(contribution);
      }
    }
    
    // Ajouter √† entries
    entries.entries.unshift(contribution); // Ajouter au d√©but (plus r√©cent)
    
    console.log(`‚úÖ Contribution ${contribution.id} trait√©e`);
    
  } catch (error) {
    console.error(`‚ùå Erreur traitement issue #${issue.number}:`, error);
  }
}

function parseIssueBody(body) {
  // Parser le format markdown de l'issue (format Worker Cloudflare)
  const contribution = {};
  
  // Extraire les champs avec regex pour correspondre au format Worker
  const typeMatch = body.match(/\*\*Type:\*\*\s*([^\n]+)/);
  if (typeMatch) contribution.type = typeMatch[1].trim();
  
  // Essayer d'abord "Nom d'affichage" puis "Nom" en fallback
  let nameMatch = body.match(/\*\*Nom d'affichage:\*\*\s*([^\n]+)/);
  if (!nameMatch) nameMatch = body.match(/\*\*Nom:\*\*\s*([^\n]+)/);
  if (nameMatch) contribution.displayName = nameMatch[1].trim();
  
  const locationMatch = body.match(/\*\*Lieu:\*\*\s*([^\n]+)/);
  if (locationMatch) contribution.locationId = locationMatch[1].trim();
  
  const eventMatch = body.match(/\*\*√âv√©nement:\*\*\s*([^\n]+)/);
  if (eventMatch) contribution.eventId = eventMatch[1].trim();
  
  // Chercher la description (format Worker)
  let contentMatch = body.match(/\*\*Description:\*\*\s*([^\n]+(?:\n(?!\*\*)[^\n]*)*)/);
  if (!contentMatch) {
    // Fallback vers autres formats
    contentMatch = body.match(/\*\*(?:Contenu|T√©moignage):\*\*\s*([^\n]+(?:\n(?!\*\*)[^\n]*)*)/);
  }
  if (contentMatch) {
    contribution.content = contentMatch[1].trim();
  }
  
  // Si pas de contenu trouv√© avec les labels, prendre tout le texte apr√®s les m√©tadonn√©es
  if (!contribution.content) {
    // Supprimer toutes les lignes qui commencent par **
    const textLines = body.split('\n').filter(line => !line.startsWith('**') && line.trim() !== '');
    if (textLines.length > 0) {
      contribution.content = textLines.join('\n').trim();
    }
  }
  
  // üå©Ô∏è CLOUDINARY: Extraire l'image (Cloudinary en priorit√©, base64 en fallback)
  // Cloudinary est le syst√®me principal depuis 2025 - URLs format: https://res.cloudinary.com/dpatqkgsc/...
  const cloudinaryMatch = body.match(/https:\/\/res\.cloudinary\.com\/[^\s\n)]+/);
  if (cloudinaryMatch) {
    contribution.imageUrl = cloudinaryMatch[0];
    console.log(`üå©Ô∏è URL Cloudinary trouv√©e: ${contribution.imageUrl}`);
  } else {
    // üì∑ LEGACY: Fallback vers base64 pour r√©trocompatibilit√© (ancien syst√®me)
    const imageMatch = body.match(/data:image\/[^;]+;base64,([^)]+)/);
    if (imageMatch) {
      contribution.imageData = imageMatch[1];
      console.log(`üì∑ Image base64 trouv√©e (ancien syst√®me)`);
    }
  }
  
  console.log(`üìù Parsing issue body:`, body);
  console.log(`üìù Contenu extrait: "${contribution.content || 'AUCUN'}"`);
  console.log(`üìù Type extrait: "${contribution.type || 'AUCUN'}"`);
  console.log(`üìù Nom extrait: "${contribution.displayName || 'AUCUN'}"`);
  
  return contribution;
}

async function processImage(contribution) {
  try {
    const imageBuffer = Buffer.from(contribution.imageData, 'base64');
    
    // Cr√©er les dossiers
    fs.ensureDirSync('images');
    fs.ensureDirSync('thumbnails');
    
    // Sauvegarder l'image originale
    const imagePath = path.join('images', `${contribution.id}.jpg`);
    await sharp(imageBuffer)
      .resize(1200, 900, { fit: 'inside', withoutEnlargement: true })
      .jpeg({ quality: 85 })
      .toFile(imagePath);
    
    // Cr√©er la miniature
    const thumbnailPath = path.join('thumbnails', `${contribution.id}.jpg`);
    await sharp(imageBuffer)
      .resize(300, 300, { fit: 'cover' })
      .jpeg({ quality: 80 })
      .toFile(thumbnailPath);
    
    // URLs pour l'acc√®s
    contribution.imageUrl = `https://github.com/${REPO_OWNER}/${REPO_NAME}/raw/main/images/${contribution.id}.jpg`;
    contribution.thumbnailUrl = `https://github.com/${REPO_OWNER}/${REPO_NAME}/raw/main/thumbnails/${contribution.id}.jpg`;
    
    // Supprimer les donn√©es base64 (plus besoin)
    delete contribution.imageData;
    
    console.log(`üñºÔ∏è Image ${contribution.id} trait√©e`);
    
  } catch (error) {
    console.error('‚ùå Erreur traitement image:', error);
    throw error;
  }
}

async function markIssueAsRejected(closedIssue, entries) {
  try {
    console.log(`üóëÔ∏è Marquage issue ferm√©e #${closedIssue.number} comme "rejected"`);
    
    // Chercher l'entr√©e correspondante dans entries.json
    const issueId = `issue-${closedIssue.number}`;
    const entryIndex = entries.entries.findIndex(entry => entry.id === issueId);
    
    if (entryIndex !== -1) {
      // Marquer l'entr√©e comme "rejected"
      entries.entries[entryIndex].moderation = {
        status: 'rejected',
        moderatedAt: new Date().toISOString(),
        reason: 'Supprim√©e par un administrateur'
      };
      console.log(`‚úÖ Entr√©e ${issueId} marqu√©e comme "rejected"`);
    } else {
      console.log(`‚ö†Ô∏è Entr√©e ${issueId} non trouv√©e dans entries.json`);
    }
    
  } catch (error) {
    console.error(`‚ùå Erreur marquage issue ferm√©e #${closedIssue.number}:`, error);
  }
}

main();
